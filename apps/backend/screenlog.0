2024-09-08 23:31:25,261 - uvicorn.error - INFO - Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
2024-09-08 23:31:25,261 - uvicorn.error - INFO - Started parent process [2215]
2024-09-08 23:31:25,366 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-08 23:31:25,379 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-08 23:31:25,968 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:25,970 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:25,979 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:25,979 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:25,987 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:25,988 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:25,996 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:25,996 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:26,021 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:26,023 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:26,032 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:26,032 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:26,040 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:26,040 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:26,048 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:31:26,049 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Started server process [2218]
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Waiting for application startup.
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Started server process [2217]
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Waiting for application startup.
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Application startup complete.
2024-09-08 23:31:28,004 - uvicorn.error - INFO - Application startup complete.
2024-09-08 23:35:35,930 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Hello'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:35:36,007 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:35:36,009 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:35:36,329 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f51b9a91f50>
2024-09-08 23:35:36,330 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f51d143e3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:35:36,343 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f51b9a97a10>
2024-09-08 23:35:36,343 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:35:36,343 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:35:36,343 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:35:36,344 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:35:36,344 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:35:36,522 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:35:36,556 - routes.generate - INFO - Generation thread 139988376463104 started
2024-09-08 23:35:38,427 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:35:38 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:36:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:35:37Z'), (b'request-id', b'req_018GzahofiXjv2v734xBFGnv'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c1842fc2239e-SJC')])
2024-09-08 23:35:38,427 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:35:38,438 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:35:38 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:36:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:35:37Z', 'request-id': 'req_018GzahofiXjv2v734xBFGnv', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c1842fc2239e-SJC'})
2024-09-08 23:35:38,450 - anthropic._base_client - DEBUG - request_id: req_018GzahofiXjv2v734xBFGnv
2024-09-08 23:35:38,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:35:41,161 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:35:41,162 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:35:41,162 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:35:41,330 - routes.generate - INFO - Generation thread 139988376463104 completed
2024-09-08 23:35:41,330 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:36:05,269 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Explain what a GAN is'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:36:05,269 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:36:05,270 - httpcore.connection - DEBUG - close.started
2024-09-08 23:36:05,270 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:36:05,270 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:36:05,324 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5184a4ee50>
2024-09-08 23:36:05,326 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f51d143e3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:36:05,334 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5184a4f2d0>
2024-09-08 23:36:05,335 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:36:05,335 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:36:05,335 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:36:05,387 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:36:05,387 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:36:05,632 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:36:05,632 - routes.generate - INFO - Generation thread 139988376463104 started
2024-09-08 23:36:07,560 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:36:07 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:36:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:36:06Z'), (b'request-id', b'req_01XqNBQBn1BnkXns21TmsqdJ'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c2395d472578-SJC')])
2024-09-08 23:36:07,560 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:36:07,561 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:36:07 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:36:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:36:06Z', 'request-id': 'req_01XqNBQBn1BnkXns21TmsqdJ', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c2395d472578-SJC'})
2024-09-08 23:36:07,561 - anthropic._base_client - DEBUG - request_id: req_01XqNBQBn1BnkXns21TmsqdJ
2024-09-08 23:36:07,561 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:36:14,570 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:36:14,571 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:36:14,571 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:36:30,955 - routes.generate - INFO - Generation thread 139988376463104 completed
2024-09-08 23:36:30,956 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:38:29,839 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'show how attention works in transformers'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:38:29,909 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:38:29,909 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:38:29,924 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63bf5d6d90>
2024-09-08 23:38:29,924 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f63d6f0a3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:38:30,056 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63bf5323d0>
2024-09-08 23:38:30,056 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:38:30,056 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:38:30,056 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:38:30,056 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:38:30,056 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:38:30,143 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:38:30,143 - routes.generate - INFO - Generation thread 140066379679488 started
2024-09-08 23:38:30,879 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:38:30 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:39:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:38:30Z'), (b'request-id', b'req_016vpKiP5bQKFJ9q1u6aHuXF'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c5c1dc28ceaf-SJC')])
2024-09-08 23:38:30,880 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:38:30,880 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:38:30 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:39:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:38:30Z', 'request-id': 'req_016vpKiP5bQKFJ9q1u6aHuXF', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c5c1dc28ceaf-SJC'})
2024-09-08 23:38:30,880 - anthropic._base_client - DEBUG - request_id: req_016vpKiP5bQKFJ9q1u6aHuXF
2024-09-08 23:38:30,881 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:38:37,474 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:38:37,474 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:38:37,474 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:38:45,925 - routes.generate - INFO - Generation thread 140066379679488 completed
2024-09-08 23:38:45,925 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:38:48,396 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Draw a tree'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:38:48,397 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:38:48,397 - httpcore.connection - DEBUG - close.started
2024-09-08 23:38:48,398 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:38:48,399 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:38:48,454 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f51842bec50>
2024-09-08 23:38:48,454 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f51d143e3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:38:48,464 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f51842bee90>
2024-09-08 23:38:48,512 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:38:48,517 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:38:48,517 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:38:48,517 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:38:48,517 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:38:48,685 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:38:48,702 - routes.generate - INFO - Generation thread 139988376463104 started
2024-09-08 23:38:50,206 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:38:50 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:39:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:38:49Z'), (b'request-id', b'req_016VjMMuATjtkWVyLHLZ5mnQ'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c6353c16fa2a-SJC')])
2024-09-08 23:38:50,206 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:38:50,213 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:38:50 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:39:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:38:49Z', 'request-id': 'req_016VjMMuATjtkWVyLHLZ5mnQ', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c6353c16fa2a-SJC'})
2024-09-08 23:38:50,248 - anthropic._base_client - DEBUG - request_id: req_016VjMMuATjtkWVyLHLZ5mnQ
2024-09-08 23:38:50,248 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:38:53,955 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:38:53,955 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:38:53,955 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:38:57,944 - routes.generate - INFO - Generation thread 139988376463104 completed
2024-09-08 23:38:57,944 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:39:40,005 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain attention is all you need'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:39:40,005 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:39:40,006 - httpcore.connection - DEBUG - close.started
2024-09-08 23:39:40,006 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:39:40,006 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:39:40,063 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f638eeb3c10>
2024-09-08 23:39:40,064 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f63d6f0a3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:39:40,074 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f638eeb09d0>
2024-09-08 23:39:40,075 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:39:40,075 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:39:40,075 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:39:40,076 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:39:40,076 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:39:40,246 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:39:40,253 - routes.generate - INFO - Generation thread 140066379679488 started
2024-09-08 23:39:41,670 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:39:41 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:40:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:39:40Z'), (b'request-id', b'req_01SesRFrEsdu47PXrHZe6e44'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c77778c51566-SJC')])
2024-09-08 23:39:41,693 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:39:41,720 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:39:41 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:40:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:39:40Z', 'request-id': 'req_01SesRFrEsdu47PXrHZe6e44', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c77778c51566-SJC'})
2024-09-08 23:39:41,720 - anthropic._base_client - DEBUG - request_id: req_01SesRFrEsdu47PXrHZe6e44
2024-09-08 23:39:41,796 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:39:51,567 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:39:51,602 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:39:51,608 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:40:05,994 - routes.generate - INFO - Generation thread 140066379679488 completed
2024-09-08 23:40:05,994 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:41:00,210 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain transformers architecture'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:41:00,210 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:41:00,211 - httpcore.connection - DEBUG - close.started
2024-09-08 23:41:00,211 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:41:00,211 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:41:00,228 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f517e7b9090>
2024-09-08 23:41:00,262 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f51d143e3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:41:00,276 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f517e702290>
2024-09-08 23:41:00,276 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:41:00,333 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:41:00,333 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:41:00,333 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:41:00,333 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:41:00,556 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:41:00,556 - routes.generate - INFO - Generation thread 139988376463104 started
2024-09-08 23:41:13,489 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:41:13 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:41:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:41:01Z'), (b'request-id', b'req_01JijVwpC6rxcVV554tw34LM'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02c96d1ffbfa7a-SJC')])
2024-09-08 23:41:13,526 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:41:13,570 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:41:13 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:41:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:41:01Z', 'request-id': 'req_01JijVwpC6rxcVV554tw34LM', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02c96d1ffbfa7a-SJC'})
2024-09-08 23:41:13,609 - anthropic._base_client - DEBUG - request_id: req_01JijVwpC6rxcVV554tw34LM
2024-09-08 23:41:13,609 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:41:20,439 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:41:20,482 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:41:20,555 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:41:33,250 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain matrix multiplication'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:41:33,251 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:41:33,252 - httpcore.connection - DEBUG - close.started
2024-09-08 23:41:33,252 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:41:33,252 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:41:33,259 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63a56b18d0>
2024-09-08 23:41:33,259 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f63d6f0a3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:41:33,327 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f638f045c10>
2024-09-08 23:41:33,327 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:41:33,331 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:41:33,332 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:41:33,332 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:41:33,332 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:41:33,589 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:41:33,600 - routes.generate - INFO - Generation thread 140066379679488 started
2024-09-08 23:41:34,874 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:41:34 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:42:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:41:34Z'), (b'request-id', b'req_019njcs6UZV7U2csWm7DQRJR'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02ca3b5dc67ad0-SJC')])
2024-09-08 23:41:34,876 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:41:34,876 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:41:34 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:42:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:41:34Z', 'request-id': 'req_019njcs6UZV7U2csWm7DQRJR', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02ca3b5dc67ad0-SJC'})
2024-09-08 23:41:34,877 - anthropic._base_client - DEBUG - request_id: req_019njcs6UZV7U2csWm7DQRJR
2024-09-08 23:41:34,878 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:41:41,943 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:41:41,944 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:41:41,944 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:41:51,249 - routes.generate - INFO - Generation thread 139988376463104 completed
2024-09-08 23:41:51,249 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:41:51,727 - routes.generate - INFO - Generation thread 140066379679488 completed
2024-09-08 23:41:51,727 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:43:43,515 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'hello'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:43:43,516 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:43:43,516 - httpcore.connection - DEBUG - close.started
2024-09-08 23:43:43,517 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:43:43,517 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:43:43,572 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63a5c94f10>
2024-09-08 23:43:43,572 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f63d6f0a3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:43:43,580 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63a5c96310>
2024-09-08 23:43:43,580 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:43:43,582 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:43:43,631 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:43:43,635 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:43:43,636 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:43:43,831 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:43:43,850 - routes.generate - INFO - Generation thread 140066379679488 started
2024-09-08 23:43:44,364 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:43:44 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:44:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:43:44Z'), (b'request-id', b'req_015ajUJ4r5wfq3RvccqJ2pU5'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02cd69698a9803-SJC')])
2024-09-08 23:43:44,365 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:43:44,365 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:43:44 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:44:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:43:44Z', 'request-id': 'req_015ajUJ4r5wfq3RvccqJ2pU5', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02cd69698a9803-SJC'})
2024-09-08 23:43:44,365 - anthropic._base_client - DEBUG - request_id: req_015ajUJ4r5wfq3RvccqJ2pU5
2024-09-08 23:43:44,365 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:43:45,728 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:43:45,728 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:43:45,728 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:43:48,050 - routes.generate - INFO - Generation thread 140066379679488 completed
2024-09-08 23:43:48,050 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:45:19,066 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize matrix multiplication'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:45:19,066 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:45:19,067 - httpcore.connection - DEBUG - close.started
2024-09-08 23:45:19,067 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:45:19,067 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:45:19,087 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63a5971bd0>
2024-09-08 23:45:19,122 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f63d6f0a3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:45:19,132 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f63a5fdfd50>
2024-09-08 23:45:19,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:45:19,133 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:45:19,133 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:45:19,133 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:45:19,135 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:45:19,360 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:45:19,377 - routes.generate - INFO - Generation thread 140066379679488 started
2024-09-08 23:45:19,870 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:45:19 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:45:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:45:19Z'), (b'request-id', b'req_014GmDLdZYWkupUD8ab4k4na'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02cfbe9a59969f-SJC')])
2024-09-08 23:45:19,871 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:45:19,871 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:45:19 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:45:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:45:19Z', 'request-id': 'req_014GmDLdZYWkupUD8ab4k4na', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02cfbe9a59969f-SJC'})
2024-09-08 23:45:19,871 - anthropic._base_client - DEBUG - request_id: req_014GmDLdZYWkupUD8ab4k4na
2024-09-08 23:45:19,872 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:45:29,990 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:45:29,991 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:45:29,991 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:45:38,708 - routes.generate - INFO - Generation thread 140066379679488 completed
2024-09-08 23:45:38,708 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:47:01,116 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'show me how bicycles work.'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:47:01,120 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:47:01,120 - httpcore.connection - DEBUG - close.started
2024-09-08 23:47:01,121 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:47:01,121 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:47:01,176 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f517e03b2d0>
2024-09-08 23:47:01,176 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f51d143e3c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:47:01,183 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f517e044750>
2024-09-08 23:47:01,183 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:47:01,183 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:47:01,183 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:47:01,184 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:47:01,184 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:47:01,505 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:47:01,505 - routes.generate - INFO - Generation thread 139988746364672 started
2024-09-08 23:47:03,136 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:47:03 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:47:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:47:01Z'), (b'request-id', b'req_01GciXPQzY8b19Dym13jT2ca'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02d23c6e9f9658-SJC')])
2024-09-08 23:47:03,137 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:47:03,137 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:47:03 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:47:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:47:01Z', 'request-id': 'req_01GciXPQzY8b19Dym13jT2ca', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02d23c6e9f9658-SJC'})
2024-09-08 23:47:03,138 - anthropic._base_client - DEBUG - request_id: req_01GciXPQzY8b19Dym13jT2ca
2024-09-08 23:47:03,180 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:47:10,158 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:47:10,159 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:47:10,159 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:47:20,895 - routes.generate - INFO - Generation thread 139988746364672 completed
2024-09-08 23:47:20,895 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:50:21,830 - uvicorn.error - ERROR - [Errno 98] Address already in use
2024-09-08 23:51:34,763 - uvicorn.error - INFO - Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
2024-09-08 23:51:34,763 - uvicorn.error - INFO - Started parent process [3160]
2024-09-08 23:51:34,870 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-08 23:51:34,884 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-08 23:51:35,498 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,500 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,509 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,510 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,518 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,518 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,526 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,527 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,540 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,542 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,551 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,552 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,560 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,560 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:35,569 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-08 23:51:35,569 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-08 23:51:36,238 - uvicorn.error - INFO - Started server process [3162]
2024-09-08 23:51:36,238 - uvicorn.error - INFO - Waiting for application startup.
2024-09-08 23:51:36,239 - uvicorn.error - INFO - Application startup complete.
2024-09-08 23:51:36,248 - uvicorn.error - INFO - Started server process [3163]
2024-09-08 23:51:36,248 - uvicorn.error - INFO - Waiting for application startup.
2024-09-08 23:51:36,248 - uvicorn.error - INFO - Application startup complete.
2024-09-08 23:51:44,967 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a square'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:51:45,028 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:51:45,029 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:51:45,180 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f315ef8e810>
2024-09-08 23:51:45,180 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:51:45,189 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f315ef8ec50>
2024-09-08 23:51:45,190 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:51:45,190 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:51:45,190 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:51:45,201 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:51:45,201 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:51:45,235 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:51:45,273 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-08 23:51:45,897 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:51:45 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:52:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:51:45Z'), (b'request-id', b'req_012wB7YdBrDoroF24hV4cqji'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02d92b7b7cfae7-SJC')])
2024-09-08 23:51:45,900 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:51:45,905 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:51:45 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:52:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:51:45Z', 'request-id': 'req_012wB7YdBrDoroF24hV4cqji', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02d92b7b7cfae7-SJC'})
2024-09-08 23:51:45,920 - anthropic._base_client - DEBUG - request_id: req_012wB7YdBrDoroF24hV4cqji
2024-09-08 23:51:45,928 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:51:46,152 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:51:46,161 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:51:46,238 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:51:46,701 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-08 23:51:46,702 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:52:30,801 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a triangle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:52:30,801 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:52:30,802 - httpcore.connection - DEBUG - close.started
2024-09-08 23:52:30,802 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:52:30,803 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:52:30,866 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f315ef4ccd0>
2024-09-08 23:52:30,867 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:52:30,874 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f315efd6050>
2024-09-08 23:52:30,875 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:52:30,875 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:52:30,875 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:52:30,875 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:52:30,875 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:52:31,089 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:52:31,097 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-08 23:52:31,574 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:52:31 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:53:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:52:31Z'), (b'request-id', b'req_01EsLAA5Mx2FwxCT3q1j2FR1'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02da48fcef9e56-SJC')])
2024-09-08 23:52:31,575 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:52:31,575 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:52:31 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:53:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:52:31Z', 'request-id': 'req_01EsLAA5Mx2FwxCT3q1j2FR1', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02da48fcef9e56-SJC'})
2024-09-08 23:52:31,575 - anthropic._base_client - DEBUG - request_id: req_01EsLAA5Mx2FwxCT3q1j2FR1
2024-09-08 23:52:31,576 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:52:31,954 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:52:31,954 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:52:31,954 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:52:32,536 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-08 23:52:32,536 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:55:52,148 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize 2x2 matrix multiplication'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:55:52,215 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:55:52,215 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:55:52,223 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe074696a50>
2024-09-08 23:55:52,223 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe08bfc63c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:55:52,339 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe074696c90>
2024-09-08 23:55:52,341 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:55:52,344 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:55:52,344 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:55:52,344 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:55:52,344 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:55:52,506 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:55:52,507 - routes.generate - INFO - Generation thread 140602001536768 started
2024-09-08 23:55:52,945 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:55:52 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:56:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:55:53Z'), (b'request-id', b'req_01PgUCnMagNGkpUGnVYy2sTP'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02df342f786441-SJC')])
2024-09-08 23:55:52,945 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:55:52,946 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:55:52 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:56:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:55:53Z', 'request-id': 'req_01PgUCnMagNGkpUGnVYy2sTP', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02df342f786441-SJC'})
2024-09-08 23:55:52,946 - anthropic._base_client - DEBUG - request_id: req_01PgUCnMagNGkpUGnVYy2sTP
2024-09-08 23:55:52,946 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:56:02,599 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:56:02,599 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:56:02,599 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:56:04,774 - routes.generate - INFO - Generation thread 140602001536768 completed
2024-09-08 23:56:04,774 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:57:01,913 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain dynamic programming leetcode question'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:57:01,913 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:57:01,914 - httpcore.connection - DEBUG - close.started
2024-09-08 23:57:01,915 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:57:01,915 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:57:01,972 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe074675e10>
2024-09-08 23:57:01,972 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe08bfc63c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:57:01,986 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe03afc9590>
2024-09-08 23:57:01,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:57:02,036 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:57:02,037 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:57:02,038 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:57:02,038 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:57:02,272 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:57:02,272 - routes.generate - INFO - Generation thread 140602001536768 started
2024-09-08 23:57:02,749 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:57:02 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:57:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:57:02Z'), (b'request-id', b'req_01QjBszoKdkkqNdCXGUFYeVd'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02e0e7bb04fa1e-SJC')])
2024-09-08 23:57:02,754 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:57:02,754 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:57:02 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:57:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:57:02Z', 'request-id': 'req_01QjBszoKdkkqNdCXGUFYeVd', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02e0e7bb04fa1e-SJC'})
2024-09-08 23:57:02,754 - anthropic._base_client - DEBUG - request_id: req_01QjBszoKdkkqNdCXGUFYeVd
2024-09-08 23:57:02,755 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:57:08,092 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:57:08,093 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:57:08,093 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:57:08,701 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'what is the equation of a circle?'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:57:08,701 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:57:08,704 - httpcore.connection - DEBUG - close.started
2024-09-08 23:57:08,704 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:57:08,712 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:57:08,785 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f314c1466d0>
2024-09-08 23:57:08,785 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:57:08,802 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f314c3db990>
2024-09-08 23:57:08,802 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:57:08,803 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:57:08,803 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:57:08,803 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:57:08,803 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:57:09,045 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:57:09,045 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-08 23:57:10,817 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:57:10 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:57:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:57:09Z'), (b'request-id', b'req_01UpGTKbwXzGEezEesHnWrcm'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02e1120a46cf2b-SJC')])
2024-09-08 23:57:10,823 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:57:10,833 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:57:10 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:57:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:57:09Z', 'request-id': 'req_01UpGTKbwXzGEezEesHnWrcm', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02e1120a46cf2b-SJC'})
2024-09-08 23:57:10,833 - anthropic._base_client - DEBUG - request_id: req_01UpGTKbwXzGEezEesHnWrcm
2024-09-08 23:57:10,834 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:57:13,214 - routes.generate - INFO - Generation thread 140602001536768 completed
2024-09-08 23:57:13,214 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:57:14,129 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:57:14,129 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:57:14,129 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:57:19,108 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-08 23:57:19,108 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:57:50,031 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'how do you find the saddle point of a 3d curve?'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:57:50,032 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:57:50,032 - httpcore.connection - DEBUG - close.started
2024-09-08 23:57:50,033 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:57:50,033 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:57:50,087 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe0597a5010>
2024-09-08 23:57:50,088 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe08bfc63c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:57:50,099 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe059768cd0>
2024-09-08 23:57:50,099 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:57:50,150 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:57:50,151 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:57:50,152 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:57:50,152 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:57:50,327 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:57:50,458 - routes.generate - INFO - Generation thread 140602001536768 started
2024-09-08 23:57:50,877 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:57:50 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:58:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:57:50Z'), (b'request-id', b'req_013c4xYtwzoNntntrJXpoqdu'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02e2146dcc679f-SJC')])
2024-09-08 23:57:50,877 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:57:50,878 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:57:50 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:58:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:57:50Z', 'request-id': 'req_013c4xYtwzoNntntrJXpoqdu', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02e2146dcc679f-SJC'})
2024-09-08 23:57:50,878 - anthropic._base_client - DEBUG - request_id: req_013c4xYtwzoNntntrJXpoqdu
2024-09-08 23:57:50,879 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:57:55,455 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:57:55,455 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:57:55,455 - httpcore.http11 - DEBUG - response_closed.complete
Exception in thread Thread-15 (run_scene):
Traceback (most recent call last):
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 1038, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 975, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/generate_manim_python.py", line 60, in run_scene
    scene.render()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 235, in render
    self.construct()
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/scenes.py", line 27, in construct
    self.interactive_embed(self.commands, self.start_time)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1429, in interactive_embed
    self.interact(shell, keyboard_thread)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1484, in interact
    getattr(self, method)(*args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1114, in play
    self.renderer.play(self, *args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 421, in play
    scene.begin_animations()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1246, in begin_animations
    animation.begin()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/animation/transform.py", line 202, in begin
    self.mobject.align_data_and_family(self.target_copy)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/mobject/opengl/opengl_mobject.py", line 2460, in align_data_and_family
    self.align_data(mobject)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/mobject/opengl/opengl_mobject.py", line 2475, in align_data
    if len(arr2) > len(arr1):
       ^^^^^^^^^
TypeError: object of type 'float' has no len()
2024-09-08 23:57:58,767 - routes.generate - INFO - Generation thread 140602001536768 completed
2024-09-08 23:57:58,767 - routes.generate - INFO - Current active threads: 0
2024-09-08 23:58:59,983 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'please show me how to take the derivative of x^2'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-08 23:58:59,984 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-08 23:58:59,984 - httpcore.connection - DEBUG - close.started
2024-09-08 23:58:59,985 - httpcore.connection - DEBUG - close.complete
2024-09-08 23:58:59,985 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-08 23:59:00,044 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f31300f5750>
2024-09-08 23:59:00,046 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-08 23:59:00,103 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f313810d9d0>
2024-09-08 23:59:00,105 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-08 23:59:00,107 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-08 23:59:00,107 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-08 23:59:00,107 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-08 23:59:00,107 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-08 23:59:00,222 - routes.generate - INFO - Current active threads: 1
2024-09-08 23:59:00,222 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-08 23:59:00,800 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 08 Sep 2024 23:59:00 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-08T23:59:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-08T23:59:00Z'), (b'request-id', b'req_01RP2owbScnGQYF1FMZXXtKb'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02e3c9affa7ab6-SJC')])
2024-09-08 23:59:00,801 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-08 23:59:00,801 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sun, 08 Sep 2024 23:59:00 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-08T23:59:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-08T23:59:00Z', 'request-id': 'req_01RP2owbScnGQYF1FMZXXtKb', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02e3c9affa7ab6-SJC'})
2024-09-08 23:59:00,801 - anthropic._base_client - DEBUG - request_id: req_01RP2owbScnGQYF1FMZXXtKb
2024-09-08 23:59:00,802 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-08 23:59:04,383 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-08 23:59:04,448 - httpcore.http11 - DEBUG - response_closed.started
2024-09-08 23:59:04,452 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-08 23:59:14,966 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-08 23:59:14,966 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:03:33,402 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a circle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:03:33,402 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:03:33,402 - httpcore.connection - DEBUG - close.started
2024-09-09 00:03:33,403 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:03:33,403 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:03:33,460 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f313a55df50>
2024-09-09 00:03:33,460 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:03:33,471 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3111308b10>
2024-09-09 00:03:33,518 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:03:33,524 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:03:33,524 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:03:33,525 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:03:33,525 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:03:33,799 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:03:33,799 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-09 00:03:34,213 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:03:34 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:04:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:03:34Z'), (b'request-id', b'req_01SDneN3CKEaffNq7JnsgTsL'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02ea768c7f235c-SJC')])
2024-09-09 00:03:34,314 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:03:34,368 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:03:34 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:04:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:03:34Z', 'request-id': 'req_01SDneN3CKEaffNq7JnsgTsL', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02ea768c7f235c-SJC'})
2024-09-09 00:03:34,368 - anthropic._base_client - DEBUG - request_id: req_01SDneN3CKEaffNq7JnsgTsL
2024-09-09 00:03:34,368 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:03:34,519 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:03:34,520 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:03:34,520 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:03:35,176 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-09 00:03:35,176 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:05:18,766 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize a 2x2 matrix step by step '}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:05:18,766 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:05:18,766 - httpcore.connection - DEBUG - close.started
2024-09-09 00:05:18,767 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:05:18,767 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:05:18,822 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f313a581bd0>
2024-09-09 00:05:18,822 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:05:18,832 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f313a4799d0>
2024-09-09 00:05:18,832 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:05:18,833 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:05:18,833 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:05:18,835 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:05:18,884 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:05:19,031 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:05:19,031 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-09 00:05:19,673 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:05:19 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:05:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:05:19Z'), (b'request-id', b'req_01CAtDWU9JGDoyj9MfYSSavn'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02ed08b9d8984e-SJC')])
2024-09-09 00:05:19,673 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:05:19,674 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:05:19 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:05:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:05:19Z', 'request-id': 'req_01CAtDWU9JGDoyj9MfYSSavn', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02ed08b9d8984e-SJC'})
2024-09-09 00:05:19,674 - anthropic._base_client - DEBUG - request_id: req_01CAtDWU9JGDoyj9MfYSSavn
2024-09-09 00:05:19,674 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:05:24,221 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:05:24,221 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:05:24,221 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:05:27,079 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-09 00:05:27,079 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:08:18,497 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'hello'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:08:18,498 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:08:18,498 - httpcore.connection - DEBUG - close.started
2024-09-09 00:08:18,498 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:08:18,499 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:08:18,552 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f30d6047ed0>
2024-09-09 00:08:18,552 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:08:18,564 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f30d603b6d0>
2024-09-09 00:08:18,564 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:08:18,564 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:08:18,564 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:08:18,564 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:08:18,565 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:08:19,047 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:08:19,064 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-09 00:08:20,560 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:08:20 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:08:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:08:19Z'), (b'request-id', b'req_01D1PHJrS7opR8ytKGWReRbp'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02f16c093a1586-SJC')])
2024-09-09 00:08:20,561 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:08:20,561 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:08:20 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:08:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:08:19Z', 'request-id': 'req_01D1PHJrS7opR8ytKGWReRbp', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02f16c093a1586-SJC'})
2024-09-09 00:08:20,564 - anthropic._base_client - DEBUG - request_id: req_01D1PHJrS7opR8ytKGWReRbp
2024-09-09 00:08:20,571 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:08:20,589 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'animate the impact of changing elements related to the ISO Triangle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:08:20,590 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:08:20,590 - httpcore.connection - DEBUG - close.started
2024-09-09 00:08:20,590 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:08:20,591 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:08:20,611 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe021691310>
2024-09-09 00:08:20,654 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe08bfc63c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:08:20,664 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe0216867d0>
2024-09-09 00:08:20,664 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:08:20,665 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:08:20,665 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:08:20,665 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:08:20,665 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:08:20,979 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:08:20,979 - routes.generate - INFO - Generation thread 140602001536768 started
2024-09-09 00:08:22,122 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:08:22 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:08:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:08:21Z'), (b'request-id', b'req_01LJ6Y7PBYoMfyN1toYi4UV2'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02f1792bcff98b-SJC')])
2024-09-09 00:08:22,122 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:08:22,128 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:08:22 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:08:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:08:21Z', 'request-id': 'req_01LJ6Y7PBYoMfyN1toYi4UV2', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02f1792bcff98b-SJC'})
2024-09-09 00:08:22,128 - anthropic._base_client - DEBUG - request_id: req_01LJ6Y7PBYoMfyN1toYi4UV2
2024-09-09 00:08:22,129 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:08:22,563 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:08:22,563 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:08:22,563 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:08:24,903 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-09 00:08:24,903 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:08:26,192 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:08:26,192 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:08:26,193 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:08:30,438 - routes.generate - INFO - Generation thread 140602001536768 completed
2024-09-09 00:08:30,438 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:18:09,836 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Explain covid'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:18:09,836 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:18:09,837 - httpcore.connection - DEBUG - close.started
2024-09-09 00:18:09,837 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:18:09,837 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:18:09,902 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f30d6040c50>
2024-09-09 00:18:09,902 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f31769123c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:18:09,913 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f30d6333950>
2024-09-09 00:18:09,913 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:18:09,913 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:18:09,914 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:18:09,914 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:18:09,914 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:18:10,221 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:18:10,221 - routes.generate - INFO - Generation thread 139849424942848 started
2024-09-09 00:18:11,576 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:18:11 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:18:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:18:10Z'), (b'request-id', b'req_01LV71RfAiVkdRm28kA4B9dt'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c02ffdbfccb96ba-SJC')])
2024-09-09 00:18:11,576 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:18:11,576 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:18:11 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:18:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:18:10Z', 'request-id': 'req_01LV71RfAiVkdRm28kA4B9dt', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c02ffdbfccb96ba-SJC'})
2024-09-09 00:18:11,577 - anthropic._base_client - DEBUG - request_id: req_01LV71RfAiVkdRm28kA4B9dt
2024-09-09 00:18:11,577 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:18:15,935 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:18:15,936 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:18:15,937 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:18:30,676 - routes.generate - INFO - Generation thread 139849424942848 completed
2024-09-09 00:18:30,676 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:19:07,066 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Illustrate the Doppler effect'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:19:07,067 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:19:07,067 - httpcore.connection - DEBUG - close.started
2024-09-09 00:19:07,068 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:19:07,068 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:19:07,071 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe0599eb9d0>
2024-09-09 00:19:07,086 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe08bfc63c0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:19:07,133 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe05a9ac910>
2024-09-09 00:19:07,134 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:19:07,134 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:19:07,134 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:19:07,134 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:19:07,135 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:19:07,324 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:19:07,325 - routes.generate - INFO - Generation thread 140602001536768 started
2024-09-09 00:19:09,316 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:19:09 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:19:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:19:07Z'), (b'request-id', b'req_01DUc48EXKeSQLKRT9ZvtsPp'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0301419e8896dd-SJC')])
2024-09-09 00:19:09,333 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:19:09,333 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:19:09 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:19:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:19:07Z', 'request-id': 'req_01DUc48EXKeSQLKRT9ZvtsPp', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0301419e8896dd-SJC'})
2024-09-09 00:19:09,333 - anthropic._base_client - DEBUG - request_id: req_01DUc48EXKeSQLKRT9ZvtsPp
2024-09-09 00:19:09,333 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:19:12,490 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:19:12,494 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:19:12,495 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:19:15,096 - routes.generate - INFO - Generation thread 140602001536768 completed
2024-09-09 00:19:15,096 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:19:41,449 - uvicorn.error - INFO - Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
2024-09-09 00:19:41,449 - uvicorn.error - INFO - Started parent process [3896]
2024-09-09 00:19:41,563 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-09 00:19:41,578 - asyncio - DEBUG - Using selector: EpollSelector
2024-09-09 00:19:42,263 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,265 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,274 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,275 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,283 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,284 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,288 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,290 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,292 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,293 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,300 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,300 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,309 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,310 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:42,318 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-09-09 00:19:42,319 - httpx - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'
2024-09-09 00:19:43,005 - uvicorn.error - INFO - Started server process [3898]
2024-09-09 00:19:43,006 - uvicorn.error - INFO - Waiting for application startup.
2024-09-09 00:19:43,006 - uvicorn.error - INFO - Application startup complete.
2024-09-09 00:19:43,075 - uvicorn.error - INFO - Started server process [3899]
2024-09-09 00:19:43,076 - uvicorn.error - INFO - Waiting for application startup.
2024-09-09 00:19:43,076 - uvicorn.error - INFO - Application startup complete.
2024-09-09 00:21:04,272 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize how embedded c development works for flight computers'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:21:04,272 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:21:04,343 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:21:04,343 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:21:04,350 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8655c9e650>
2024-09-09 00:21:04,350 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:21:04,360 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8655cb65d0>
2024-09-09 00:21:04,360 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:21:04,485 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:21:04,487 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:21:04,488 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:21:04,488 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:21:04,540 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:21:04,540 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 00:21:06,710 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:21:06 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:21:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:21:05Z'), (b'request-id', b'req_01C9ocyRVpKDUaX7yD239Zyg'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c03041f0928fa5a-SJC')])
2024-09-09 00:21:06,711 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:21:06,717 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:21:06 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:21:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:21:05Z', 'request-id': 'req_01C9ocyRVpKDUaX7yD239Zyg', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c03041f0928fa5a-SJC'})
2024-09-09 00:21:06,717 - anthropic._base_client - DEBUG - request_id: req_01C9ocyRVpKDUaX7yD239Zyg
2024-09-09 00:21:06,729 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:21:14,048 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:21:14,048 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:21:14,048 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:21:15,177 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain a Rieman sum'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:21:15,179 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:21:15,192 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:21:15,193 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:21:15,261 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cbbf0bf90>
2024-09-09 00:21:15,261 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:21:15,272 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cbbf08a50>
2024-09-09 00:21:15,272 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:21:15,272 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:21:15,273 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:21:15,273 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:21:15,275 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:21:15,517 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:21:15,517 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 00:21:16,894 - uvicorn.error - ERROR - Exception in ASGI application
Traceback (most recent call last):
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py", line 428, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 78, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/fastapi/applications.py", line 276, in __call__
    await super().__call__(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/applications.py", line 122, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/errors.py", line 184, in __call__
    raise exc
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/cors.py", line 84, in __call__
    await self.app(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 79, in __call__
    raise exc
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py", line 21, in __call__
    raise e
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/routing.py", line 443, in handle
    await self.app(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/staticfiles.py", line 104, in __call__
    await response(scope, receive, send)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/responses.py", line 358, in __call__
    await send(
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 65, in sender
    await send(message)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/starlette/middleware/errors.py", line 159, in _send
    await send(message)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py", line 530, in send
    output = self.conn.send(event)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/h11/_connection.py", line 512, in send
    data_list = self.send_with_data_passthrough(event)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/h11/_connection.py", line 545, in send_with_data_passthrough
    writer(event, data_list.append)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/h11/_writers.py", line 65, in __call__
    self.send_data(event.data, write)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/h11/_writers.py", line 91, in send_data
    raise LocalProtocolError("Too much data for declared Content-Length")
h11._util.LocalProtocolError: Too much data for declared Content-Length
2024-09-09 00:21:17,380 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:21:17 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:21:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:21:15Z'), (b'request-id', b'req_01WcMtQztQyaXU8TLxNNmNcQ'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c03046278ed22c6-SJC')])
2024-09-09 00:21:17,381 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:21:17,385 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:21:17 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:21:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:21:15Z', 'request-id': 'req_01WcMtQztQyaXU8TLxNNmNcQ', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c03046278ed22c6-SJC'})
2024-09-09 00:21:17,385 - anthropic._base_client - DEBUG - request_id: req_01WcMtQztQyaXU8TLxNNmNcQ
2024-09-09 00:21:17,385 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:21:20,968 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:21:20,968 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 00:21:20,968 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:21:21,272 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'explain the use case of stablecoins '}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:21:21,273 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:21:21,273 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:21:21,274 - httpcore.connection - DEBUG - close.started
2024-09-09 00:21:21,277 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:21:21,278 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:21:21,301 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f861b785910>
2024-09-09 00:21:21,301 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:21:21,356 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f861b703810>
2024-09-09 00:21:21,356 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:21:21,360 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:21:21,409 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:21:21,411 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:21:21,414 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:21:21,585 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:21:21,585 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 00:21:23,252 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:21:23 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:21:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:21:22Z'), (b'request-id', b'req_01HRx9av25TAb8rCifmpUNRx'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0304887fae7ac8-SJC')])
2024-09-09 00:21:23,253 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:21:23,253 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:21:23 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:21:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:21:22Z', 'request-id': 'req_01HRx9av25TAb8rCifmpUNRx', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0304887fae7ac8-SJC'})
2024-09-09 00:21:23,259 - anthropic._base_client - DEBUG - request_id: req_01HRx9av25TAb8rCifmpUNRx
2024-09-09 00:21:23,260 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:21:23,676 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:21:23,677 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:21:23,677 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:21:25,778 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:21:25,779 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 00:21:25,779 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:21:31,489 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:21:31,489 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:21:31,489 - httpcore.http11 - DEBUG - response_closed.complete
Exception in thread Thread-9 (run_scene):
Traceback (most recent call last):
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 1038, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 975, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/generate_manim_python.py", line 60, in run_scene
    scene.render()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 235, in render
    self.construct()
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/scenes.py", line 27, in construct
    self.interactive_embed(self.commands, self.start_time)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1429, in interactive_embed
    self.interact(shell, keyboard_thread)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1484, in interact
    getattr(self, method)(*args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1114, in play
    self.renderer.play(self, *args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 421, in play
    scene.begin_animations()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1246, in begin_animations
    animation.begin()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/animation/transform.py", line 202, in begin
    self.mobject.align_data_and_family(self.target_copy)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/mobject/mobject.py", line 720, in __getattr__
    raise AttributeError(f"{type(self).__name__} object has no attribute '{attr}'")
AttributeError: ImageMobject object has no attribute 'align_data_and_family'
2024-09-09 00:21:43,914 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:21:43,914 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 00:21:43,915 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:26:46,195 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Visualize how to make eggs'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:26:46,195 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:26:46,196 - httpcore.connection - DEBUG - close.started
2024-09-09 00:26:46,196 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:26:46,196 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:26:46,196 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:26:46,262 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c87cd8190>
2024-09-09 00:26:46,262 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:26:46,273 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c87cd8d50>
2024-09-09 00:26:46,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:26:46,325 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:26:46,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:26:46,326 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:26:46,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:26:46,585 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:26:46,636 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 00:26:47,899 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:26:47 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:27:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:26:47Z'), (b'request-id', b'req_016LXX33s7DqM9JYiQiWdkNq'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c030c778a9ff9f9-SJC')])
2024-09-09 00:26:47,899 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:26:47,900 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:26:47 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:27:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:26:47Z', 'request-id': 'req_016LXX33s7DqM9JYiQiWdkNq', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c030c778a9ff9f9-SJC'})
2024-09-09 00:26:47,900 - anthropic._base_client - DEBUG - request_id: req_016LXX33s7DqM9JYiQiWdkNq
2024-09-09 00:26:47,900 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:26:56,295 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:26:56,295 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:26:56,295 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:27:06,477 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:27:06,477 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 00:27:06,477 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:27:31,262 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Visualize a computer chip'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:27:31,262 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:27:31,263 - httpcore.connection - DEBUG - close.started
2024-09-09 00:27:31,263 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:27:31,263 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:27:31,263 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:27:31,318 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4ca13f7a90>
2024-09-09 00:27:31,318 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:27:31,331 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c98145410>
2024-09-09 00:27:31,331 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:27:31,384 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:27:31,386 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:27:31,387 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:27:31,387 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:27:31,501 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:27:31,573 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 00:27:33,560 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:27:33 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:28:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:27:32Z'), (b'request-id', b'req_011L77bXADBKb7PMhbUJ6JHV'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c030d91284c2366-SJC')])
2024-09-09 00:27:33,592 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:27:33,592 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:27:33 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:28:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:27:32Z', 'request-id': 'req_011L77bXADBKb7PMhbUJ6JHV', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c030d91284c2366-SJC'})
2024-09-09 00:27:33,592 - anthropic._base_client - DEBUG - request_id: req_011L77bXADBKb7PMhbUJ6JHV
2024-09-09 00:27:33,595 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:27:38,129 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:27:38,130 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:27:38,130 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:27:46,720 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:27:46,720 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 00:27:46,720 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:28:19,269 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'animate the water cycle '}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:28:19,269 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:28:19,269 - httpcore.connection - DEBUG - close.started
2024-09-09 00:28:19,270 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:28:19,270 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:28:19,270 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:28:19,328 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f863332f0d0>
2024-09-09 00:28:19,328 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:28:19,339 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f862493f810>
2024-09-09 00:28:19,339 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:28:19,339 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:28:19,339 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:28:19,339 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:28:19,339 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:28:19,545 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:28:19,551 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 00:28:21,668 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:28:21 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:28:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:28:20Z'), (b'request-id', b'req_01FG9CfnEucFXJ1zbAEFAZGx'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c030ebcec559465-SJC')])
2024-09-09 00:28:21,669 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:28:21,669 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:28:21 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:28:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:28:20Z', 'request-id': 'req_01FG9CfnEucFXJ1zbAEFAZGx', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c030ebcec559465-SJC'})
2024-09-09 00:28:21,669 - anthropic._base_client - DEBUG - request_id: req_01FG9CfnEucFXJ1zbAEFAZGx
2024-09-09 00:28:21,669 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:28:29,344 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:28:29,345 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:28:29,345 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:28:31,353 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:28:31,353 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 00:28:31,353 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:29:53,987 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'animate the water cycle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:29:53,987 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:29:53,988 - httpcore.connection - DEBUG - close.started
2024-09-09 00:29:53,988 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:29:53,988 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:29:53,988 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:29:54,043 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb9facc50>
2024-09-09 00:29:54,043 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:29:54,053 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c87fa4150>
2024-09-09 00:29:54,101 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:29:54,105 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:29:54,106 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:29:54,107 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:29:54,107 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:29:54,329 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:29:54,352 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 00:29:54,912 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:29:54 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:30:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:29:54Z'), (b'request-id', b'req_01Ui12mxpejvQszdUhT2Nw2F'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c03110d29369872-SJC')])
2024-09-09 00:29:54,913 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:29:54,929 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:29:54 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:30:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:29:54Z', 'request-id': 'req_01Ui12mxpejvQszdUhT2Nw2F', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c03110d29369872-SJC'})
2024-09-09 00:29:54,953 - anthropic._base_client - DEBUG - request_id: req_01Ui12mxpejvQszdUhT2Nw2F
2024-09-09 00:29:54,956 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:29:59,856 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:29:59,866 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:29:59,867 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:30:08,341 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:30:08,342 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 00:30:08,342 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:39:22,911 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize reimann sum'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:39:22,912 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:39:22,912 - httpcore.connection - DEBUG - close.started
2024-09-09 00:39:22,913 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:39:22,913 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:39:22,913 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:39:22,967 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c87fd9810>
2024-09-09 00:39:22,967 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:39:22,978 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c84a53f90>
2024-09-09 00:39:23,026 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:39:23,032 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:39:23,032 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:39:23,033 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:39:23,033 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:39:23,188 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:39:23,192 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 00:39:23,669 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:39:23 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:39:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:39:23Z'), (b'request-id', b'req_01GMijSnWj3GtSfW7B89UhMM'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c031ef0fcd8ced1-SJC')])
2024-09-09 00:39:23,670 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:39:23,670 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:39:23 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:39:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:39:23Z', 'request-id': 'req_01GMijSnWj3GtSfW7B89UhMM', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c031ef0fcd8ced1-SJC'})
2024-09-09 00:39:23,670 - anthropic._base_client - DEBUG - request_id: req_01GMijSnWj3GtSfW7B89UhMM
2024-09-09 00:39:23,670 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:39:30,729 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:39:30,914 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:39:30,927 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:39:33,782 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:39:33,782 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 00:39:33,782 - routes.generate - INFO - Current active threads: 0
2024-09-09 00:41:16,014 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'vizualize minecraft'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 00:41:16,014 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 00:41:16,015 - httpcore.connection - DEBUG - close.started
2024-09-09 00:41:16,015 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 00:41:16,015 - httpcore.connection - DEBUG - close.complete
2024-09-09 00:41:16,015 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 00:41:16,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f862c1b3fd0>
2024-09-09 00:41:16,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 00:41:16,128 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f862c7d5510>
2024-09-09 00:41:16,133 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 00:41:16,134 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 00:41:16,134 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 00:41:16,134 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 00:41:16,134 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 00:41:16,324 - routes.generate - INFO - Current active threads: 1
2024-09-09 00:41:16,332 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 00:41:17,979 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 00:41:17 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T00:41:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T00:41:16Z'), (b'request-id', b'req_01RZaWzUsx9pgfsxuzWEAmMb'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0321b3dba0155d-SJC')])
2024-09-09 00:41:17,980 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 00:41:17,980 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 00:41:17 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T00:41:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T00:41:16Z', 'request-id': 'req_01RZaWzUsx9pgfsxuzWEAmMb', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0321b3dba0155d-SJC'})
2024-09-09 00:41:17,980 - anthropic._base_client - DEBUG - request_id: req_01RZaWzUsx9pgfsxuzWEAmMb
2024-09-09 00:41:17,980 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 00:41:24,534 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 00:41:24,534 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 00:41:24,534 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 00:41:29,025 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 00:41:29,026 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 00:41:29,026 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:06:44,132 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Explain dot product'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:06:44,132 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:06:44,133 - httpcore.connection - DEBUG - close.started
2024-09-09 01:06:44,133 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:06:44,133 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:06:44,133 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:06:44,187 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8624e3c710>
2024-09-09 01:06:44,187 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:06:44,248 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f862c11bad0>
2024-09-09 01:06:44,251 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:06:44,253 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:06:44,253 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:06:44,254 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:06:44,254 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:06:44,380 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:06:44,397 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:06:45,608 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:06:45 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:07:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:06:45Z'), (b'request-id', b'req_01Tro7Qe8eRxQ2GsinHrjQew'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0347029c4d7e21-SJC')])
2024-09-09 01:06:45,628 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:06:45,648 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:06:45 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:07:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:06:45Z', 'request-id': 'req_01Tro7Qe8eRxQ2GsinHrjQew', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0347029c4d7e21-SJC'})
2024-09-09 01:06:45,648 - anthropic._base_client - DEBUG - request_id: req_01Tro7Qe8eRxQ2GsinHrjQew
2024-09-09 01:06:45,648 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:06:50,006 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a circle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:06:50,007 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:06:50,007 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:06:50,009 - httpcore.connection - DEBUG - close.started
2024-09-09 01:06:50,011 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:06:50,011 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:06:50,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cada21810>
2024-09-09 01:06:50,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:06:50,083 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb9315c90>
2024-09-09 01:06:50,083 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:06:50,084 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:06:50,084 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:06:50,084 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:06:50,084 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:06:50,298 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:06:50,299 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 01:06:51,397 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:06:51,397 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:06:51,397 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:06:52,139 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:06:52 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:07:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:06:50Z'), (b'request-id', b'req_01UnJMxfy1EBK3gk79PynNP2'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0347270af0fa92-SJC')])
2024-09-09 01:06:52,140 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:06:52,141 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:06:52 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:07:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:06:50Z', 'request-id': 'req_01UnJMxfy1EBK3gk79PynNP2', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0347270af0fa92-SJC'})
2024-09-09 01:06:52,147 - anthropic._base_client - DEBUG - request_id: req_01UnJMxfy1EBK3gk79PynNP2
2024-09-09 01:06:52,147 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:06:52,422 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:06:52,423 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:06:52,423 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:06:53,182 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:06:53,182 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 01:06:53,182 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:06:58,577 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:06:58,577 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:06:58,577 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:15:46,886 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize fibonacci sequenece'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:15:46,886 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:15:46,887 - httpcore.connection - DEBUG - close.started
2024-09-09 01:15:46,887 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:15:46,887 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:15:46,887 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:15:46,944 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb930ab50>
2024-09-09 01:15:46,945 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:15:46,955 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb930acd0>
2024-09-09 01:15:46,955 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:15:47,008 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:15:47,008 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:15:47,008 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:15:47,008 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:15:47,126 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:15:47,251 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 01:15:48,517 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:15:48 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:16:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:15:47Z'), (b'request-id', b'req_01CfiC2nLN1dr6AJSugD6Syd'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c035442cd49fa7a-SJC')])
2024-09-09 01:15:48,517 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:15:48,518 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:15:48 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:16:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:15:47Z', 'request-id': 'req_01CfiC2nLN1dr6AJSugD6Syd', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c035442cd49fa7a-SJC'})
2024-09-09 01:15:48,518 - anthropic._base_client - DEBUG - request_id: req_01CfiC2nLN1dr6AJSugD6Syd
2024-09-09 01:15:48,518 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:15:53,090 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:15:53,106 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:15:53,106 - httpcore.http11 - DEBUG - response_closed.complete
Exception in thread Thread-39 (run_scene):
Traceback (most recent call last):
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 1038, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 975, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/generate_manim_python.py", line 60, in run_scene
    scene.render()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 235, in render
    self.construct()
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/scenes.py", line 27, in construct
    self.interactive_embed(self.commands, self.start_time)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1429, in interactive_embed
    self.interact(shell, keyboard_thread)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1484, in interact
    getattr(self, method)(*args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1114, in play
    self.renderer.play(self, *args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 437, in play
    scene.play_internal()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1291, in play_internal
    self.renderer.render(self, t, self.moving_mobjects)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 448, in render
    self.update_frame(scene)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 466, in update_frame
    if not mobject.should_render:
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/mobject/mobject.py", line 720, in __getattr__
    raise AttributeError(f"{type(self).__name__} object has no attribute '{attr}'")
AttributeError: VMobject object has no attribute 'should_render'
2024-09-09 01:16:15,587 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:16:15,587 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 01:16:15,587 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:16:37,063 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize fibonacci sequence using match sticks'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:16:37,064 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:16:37,065 - httpcore.connection - DEBUG - close.started
2024-09-09 01:16:37,065 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:16:37,065 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:16:37,066 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:16:37,119 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85d8844610>
2024-09-09 01:16:37,119 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:16:37,132 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85d883db90>
2024-09-09 01:16:37,133 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:16:37,185 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:16:37,186 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:16:37,187 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:16:37,187 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:16:37,314 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:16:37,315 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:16:38,349 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:16:38 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:17:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:16:37Z'), (b'request-id', b'req_01FaD9rRcNigVJJRUjFAtdMm'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c03557c6cd0faec-SJC')])
2024-09-09 01:16:38,350 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:16:38,350 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:16:38 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:17:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:16:37Z', 'request-id': 'req_01FaD9rRcNigVJJRUjFAtdMm', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c03557c6cd0faec-SJC'})
2024-09-09 01:16:38,350 - anthropic._base_client - DEBUG - request_id: req_01FaD9rRcNigVJJRUjFAtdMm
2024-09-09 01:16:38,350 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:16:42,518 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:16:42,518 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:16:42,518 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:16:50,522 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:16:50,522 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:16:50,523 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:17:10,513 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'visualize getting 1% better everyday'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:17:10,514 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:17:10,514 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:17:10,515 - httpcore.connection - DEBUG - close.started
2024-09-09 01:17:10,515 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:17:10,515 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:17:10,518 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85d8509390>
2024-09-09 01:17:10,519 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:17:10,526 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85d8475910>
2024-09-09 01:17:10,526 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:17:10,526 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:17:10,526 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:17:10,526 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:17:10,526 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:17:10,773 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:17:10,773 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:17:12,656 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:17:12 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:17:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:17:11Z'), (b'request-id', b'req_017P51LWccjt8koXBzM6jErz'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c03564ccef3cf55-SJC')])
2024-09-09 01:17:12,657 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:17:12,657 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:17:12 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:17:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:17:11Z', 'request-id': 'req_017P51LWccjt8koXBzM6jErz', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c03564ccef3cf55-SJC'})
2024-09-09 01:17:12,657 - anthropic._base_client - DEBUG - request_id: req_017P51LWccjt8koXBzM6jErz
2024-09-09 01:17:12,658 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:17:17,237 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:17:17,237 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:17:17,237 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:17:42,707 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:17:42,707 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:17:42,708 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:26:28,072 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a circle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:26:28,073 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:26:28,073 - httpcore.connection - DEBUG - close.started
2024-09-09 01:26:28,073 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:26:28,074 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:26:28,074 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:26:28,140 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb93700d0>
2024-09-09 01:26:28,143 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:26:28,218 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4cb93246d0>
2024-09-09 01:26:28,219 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:26:28,219 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:26:28,219 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:26:28,219 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:26:28,219 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:26:28,607 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:26:28,608 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 01:26:31,499 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:26:31 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:27:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:26:28Z'), (b'request-id', b'req_01Wrski4aT4gfEuR68bd635n'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0363ea6bb2fb30-SJC')])
2024-09-09 01:26:31,531 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:26:31,545 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:26:31 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:27:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:26:28Z', 'request-id': 'req_01Wrski4aT4gfEuR68bd635n', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0363ea6bb2fb30-SJC'})
2024-09-09 01:26:31,546 - anthropic._base_client - DEBUG - request_id: req_01Wrski4aT4gfEuR68bd635n
2024-09-09 01:26:31,546 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:26:31,867 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:26:31,868 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:26:31,872 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:26:32,571 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:26:32,571 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 01:26:32,571 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:26:40,341 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a square'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:26:40,341 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:26:40,342 - httpcore.connection - DEBUG - close.started
2024-09-09 01:26:40,343 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:26:40,343 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:26:40,343 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:26:40,348 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85d886d910>
2024-09-09 01:26:40,349 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:26:40,412 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8618b62990>
2024-09-09 01:26:40,412 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:26:40,413 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:26:40,413 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:26:40,413 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:26:40,413 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:26:40,715 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:26:40,715 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:26:41,365 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:26:41 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:27:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:26:41Z'), (b'request-id', b'req_01MLZcmZ43n3frW192RJLmgA'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0364369be8ce58-SJC')])
2024-09-09 01:26:41,365 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:26:41,383 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:26:41 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:27:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:26:41Z', 'request-id': 'req_01MLZcmZ43n3frW192RJLmgA', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0364369be8ce58-SJC'})
2024-09-09 01:26:41,383 - anthropic._base_client - DEBUG - request_id: req_01MLZcmZ43n3frW192RJLmgA
2024-09-09 01:26:41,384 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:26:41,563 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:26:41,563 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:26:41,568 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:26:42,178 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:26:42,178 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:26:42,178 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:26:58,664 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'graph the derivative of x^2'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:26:58,664 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:26:58,664 - httpcore.connection - DEBUG - close.started
2024-09-09 01:26:58,665 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:26:58,665 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:26:58,665 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:26:58,731 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f861893e510>
2024-09-09 01:26:58,732 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:26:58,786 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f861893c450>
2024-09-09 01:26:58,788 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:26:58,790 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:26:58,790 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:26:58,790 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:26:58,790 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:26:58,915 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:26:58,915 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:26:59,870 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:26:59 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:27:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:26:59Z'), (b'request-id', b'req_01SNu6EXPENbokHYUGodsWiw'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0364a97d25251c-SJC')])
2024-09-09 01:26:59,871 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:26:59,871 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:26:59 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:27:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:26:59Z', 'request-id': 'req_01SNu6EXPENbokHYUGodsWiw', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0364a97d25251c-SJC'})
2024-09-09 01:26:59,871 - anthropic._base_client - DEBUG - request_id: req_01SNu6EXPENbokHYUGodsWiw
2024-09-09 01:26:59,871 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:27:03,622 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:27:03,623 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:27:03,623 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:27:07,689 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:27:07,689 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:27:07,689 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:31:14,741 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'make a circle'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:31:14,742 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:31:14,742 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:31:14,742 - httpcore.connection - DEBUG - close.started
2024-09-09 01:31:14,743 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:31:14,743 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:31:14,805 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c401dddd0>
2024-09-09 01:31:14,807 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:31:14,818 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c40198490>
2024-09-09 01:31:14,818 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:31:14,871 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:31:14,871 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:31:14,871 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:31:14,871 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:31:15,092 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:31:15,114 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 01:31:17,589 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:31:17 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:31:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:31:15Z'), (b'request-id', b'req_01BGNGHCCZaPtaHBLeuwEdad'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c036ae9fbda2509-SJC')])
2024-09-09 01:31:17,589 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:31:17,589 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:31:17 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:31:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:31:15Z', 'request-id': 'req_01BGNGHCCZaPtaHBLeuwEdad', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c036ae9fbda2509-SJC'})
2024-09-09 01:31:17,590 - anthropic._base_client - DEBUG - request_id: req_01BGNGHCCZaPtaHBLeuwEdad
2024-09-09 01:31:17,590 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:31:17,882 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:31:17,883 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:31:17,888 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:31:18,567 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:31:18,567 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 01:31:18,567 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:32:24,192 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Explain the tourism industry in Nepal'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:32:24,192 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:32:24,193 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:32:24,193 - httpcore.connection - DEBUG - close.started
2024-09-09 01:32:24,193 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:32:24,194 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:32:24,250 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c40153e50>
2024-09-09 01:32:24,250 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:32:24,260 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4c40151650>
2024-09-09 01:32:24,260 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:32:24,261 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:32:24,261 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:32:24,261 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:32:24,261 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:32:24,439 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:32:24,456 - routes.generate - INFO - Generation thread 139967784122112 started
2024-09-09 01:32:25,612 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:32:25 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:32:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:32:24Z'), (b'request-id', b'req_01LGYjWMTTgzEiQs1ispF4Rn'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c036c9badd26807-SJC')])
2024-09-09 01:32:25,612 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:32:25,613 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:32:25 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:32:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:32:24Z', 'request-id': 'req_01LGYjWMTTgzEiQs1ispF4Rn', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c036c9badd26807-SJC'})
2024-09-09 01:32:25,613 - anthropic._base_client - DEBUG - request_id: req_01LGYjWMTTgzEiQs1ispF4Rn
2024-09-09 01:32:25,613 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:32:31,217 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:32:31,218 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:32:31,218 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:32:42,287 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:32:42,287 - routes.generate - INFO - Generation thread 139967784122112 completed
2024-09-09 01:32:42,287 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:33:57,322 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Animate the growth in housing demand over time relative to the growth rate of the housing stock'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:33:57,323 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:33:57,323 - httpcore.connection - DEBUG - close.started
2024-09-09 01:33:57,324 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:33:57,324 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:33:57,324 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:33:57,389 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8634e82ad0>
2024-09-09 01:33:57,389 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:33:57,398 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8634e81b10>
2024-09-09 01:33:57,398 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:33:57,398 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:33:57,398 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:33:57,399 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:33:57,399 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:33:57,633 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:33:57,633 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:33:59,234 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:33:59 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:34:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:33:58Z'), (b'request-id', b'req_01BfCLzem3vEpf7A96mg6mrA'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c036ee1bd5f26b0-SJC')])
2024-09-09 01:33:59,235 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:33:59,235 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:33:59 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:34:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:33:58Z', 'request-id': 'req_01BfCLzem3vEpf7A96mg6mrA', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c036ee1bd5f26b0-SJC'})
2024-09-09 01:33:59,235 - anthropic._base_client - DEBUG - request_id: req_01BfCLzem3vEpf7A96mg6mrA
2024-09-09 01:33:59,235 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:34:05,071 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:34:05,072 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:34:05,072 - httpcore.http11 - DEBUG - response_closed.complete
Exception in thread Thread-57 (run_scene):
Traceback (most recent call last):
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 1038, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/prod-env/lib/python3.11/threading.py", line 975, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/generate_manim_python.py", line 60, in run_scene
    scene.render()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 235, in render
    self.construct()
  File "/home/ubuntu/apps/pixa.dev/apps/backend/services/scenes.py", line 27, in construct
    self.interactive_embed(self.commands, self.start_time)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1429, in interactive_embed
    self.interact(shell, keyboard_thread)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1484, in interact
    getattr(self, method)(*args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1114, in play
    self.renderer.play(self, *args, **kwargs)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 437, in play
    scene.play_internal()
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/scene/scene.py", line 1291, in play_internal
    self.renderer.render(self, t, self.moving_mobjects)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 448, in render
    self.update_frame(scene)
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/renderer/opengl_renderer.py", line 466, in update_frame
    if not mobject.should_render:
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/envs/prod-env/lib/python3.11/site-packages/manim/mobject/mobject.py", line 720, in __getattr__
    raise AttributeError(f"{type(self).__name__} object has no attribute '{attr}'")
AttributeError: VMobject object has no attribute 'should_render'
2024-09-09 01:34:05,151 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:34:05,151 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:34:05,151 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:34:37,251 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Illustrate the doppler effect with sound waves.'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:34:37,251 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:34:37,252 - httpcore.connection - DEBUG - close.started
2024-09-09 01:34:37,252 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:34:37,252 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:34:37,252 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:34:37,317 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85bb541a90>
2024-09-09 01:34:37,317 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f866d5bec30> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:34:37,325 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f85bb548710>
2024-09-09 01:34:37,325 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:34:37,328 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:34:37,328 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:34:37,328 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:34:37,329 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:34:37,684 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:34:37,836 - routes.generate - INFO - Generation thread 140214940763904 started
2024-09-09 01:34:39,069 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:34:39 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:35:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:34:38Z'), (b'request-id', b'req_01Qs3sdSH7FkhPpMCHMC8ppR'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c036fdb4f5a1568-SJC')])
2024-09-09 01:34:39,076 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:34:39,076 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:34:39 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:35:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:34:38Z', 'request-id': 'req_01Qs3sdSH7FkhPpMCHMC8ppR', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c036fdb4f5a1568-SJC'})
2024-09-09 01:34:39,077 - anthropic._base_client - DEBUG - request_id: req_01Qs3sdSH7FkhPpMCHMC8ppR
2024-09-09 01:34:39,077 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:34:44,485 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:34:44,486 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:34:44,486 - httpcore.http11 - DEBUG - response_closed.complete
2024-09-09 01:34:51,183 - utils.monitoring - INFO - Current active subprocesses: 0
2024-09-09 01:34:51,183 - routes.generate - INFO - Generation thread 140214940763904 completed
2024-09-09 01:34:51,183 - routes.generate - INFO - Current active threads: 0
2024-09-09 01:35:11,753 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'headers': {'X-Stainless-Stream-Helper': 'messages'}, 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Show me the orbital patterns of each planet of the solar system relative to the sun.'}], 'model': 'claude-3-5-sonnet-20240620', 'system': 'You are an AI teacher. \n    \n        Generate Manim code that generates a 10-15 second animation that directly illustrates the user prompt.\n        Do not output any other text than the Manim code.\n        Do not import manim or any other libraries.\n        Do not include ANY comments (i.e. lines that start with #) \n        Do not include unnecessary newlines in the code.\n        ALWAYS start your code with a self.play() call.\n        \n        Follow these guidelines for the Manim code:\n        1. Only generate the content of the construct() method, but do not include the first line "def construct(self):".\n        2. You are using the OpenGL renderer. Never use the .to_edge() method. Instead use the .shift() method.\n        3. Use self.play() for each animation step to ensure proper sequencing.\n        4. Clear or transform previous content before introducing new elements.\n        6. Use FadeOut() or similar animations to remove objects no longer needed.\n        7. Do not ever use wait()\n        8. DO NOT ever use SVGMobject \n        9. DO NOT reference any external static assets -- including images, SVGs, videos, or audio files.\n        10. Use shapes, text, and animations that can be generated purely with manim code.\n        11. Ensure that the animation aligns perfectly with the text response. \n        12. Do not use any LIGHT color variants such as LIGHT_BLUE, LIGHT_GREEN, LIGHT_RED, etc. And never use BROWN.\n        ', 'stream': True}}
2024-09-09 01:35:11,754 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2024-09-09 01:35:11,754 - httpcore.connection - DEBUG - close.started
2024-09-09 01:35:11,754 - utils.monitoring - INFO - Current active subprocesses: 1
2024-09-09 01:35:11,755 - httpcore.connection - DEBUG - close.complete
2024-09-09 01:35:11,755 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-09-09 01:35:11,774 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4aea19b350>
2024-09-09 01:35:11,809 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4ce1b7ecc0> server_hostname='api.anthropic.com' timeout=5.0
2024-09-09 01:35:11,817 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4aea192690>
2024-09-09 01:35:11,817 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-09-09 01:35:11,817 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-09-09 01:35:11,817 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-09-09 01:35:11,817 - httpcore.http11 - DEBUG - send_request_body.complete
2024-09-09 01:35:11,817 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-09-09 01:35:12,181 - routes.generate - INFO - Current active threads: 1
2024-09-09 01:35:12,192 - routes.generate - INFO - Generation thread 139962959775488 started
2024-09-09 01:35:14,960 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Sep 2024 01:35:14 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2024-09-09T01:35:26Z'), (b'anthropic-ratelimit-tokens-limit', b'400000'), (b'anthropic-ratelimit-tokens-remaining', b'396000'), (b'anthropic-ratelimit-tokens-reset', b'2024-09-09T01:35:12Z'), (b'request-id', b'req_01GQ4VWPhFUx1gCr2vuFVpWY'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8c0370b2dee315fd-SJC')])
2024-09-09 01:35:14,961 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2024-09-09 01:35:14,961 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Mon, 09 Sep 2024 01:35:14 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2024-09-09T01:35:26Z', 'anthropic-ratelimit-tokens-limit': '400000', 'anthropic-ratelimit-tokens-remaining': '396000', 'anthropic-ratelimit-tokens-reset': '2024-09-09T01:35:12Z', 'request-id': 'req_01GQ4VWPhFUx1gCr2vuFVpWY', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '8c0370b2dee315fd-SJC'})
2024-09-09 01:35:14,961 - anthropic._base_client - DEBUG - request_id: req_01GQ4VWPhFUx1gCr2vuFVpWY
2024-09-09 01:35:14,961 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-09-09 01:35:19,289 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-09-09 01:35:19,292 - httpcore.http11 - DEBUG - response_closed.started
2024-09-09 01:35:19,292 - httpcore.http11 - DEBUG - response_closed.complete
